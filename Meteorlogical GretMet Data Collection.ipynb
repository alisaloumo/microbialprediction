## met Data
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f389675e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: netCDF4 in c:\\users\\as22dt\\anaconda3\\lib\\site-packages (1.6.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\as22dt\\anaconda3\\lib\\site-packages (from netCDF4) (1.23.5)\n",
      "Requirement already satisfied: certifi in c:\\users\\as22dt\\anaconda3\\lib\\site-packages (from netCDF4) (2022.9.14)\n",
      "Requirement already satisfied: cftime in c:\\users\\as22dt\\anaconda3\\lib\\site-packages (from netCDF4) (1.6.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\as22dt\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\as22dt\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\as22dt\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\as22dt\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\as22dt\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\as22dt\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install netCDF4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459be506",
   "metadata": {},
   "source": [
    "# The code provided will guide you in correctly specifying the variable you wish to obtain from the Net file. For example, if you are looking to extract data on precipitation, the variable in the Net file is labeled as \"precipitation_amount.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c498bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['lon', 'lat', 'day', 'crs'])\n",
      "dict_keys(['lon', 'lat', 'day', 'crs', 'precipitation_amount'])\n"
     ]
    }
   ],
   "source": [
    "from netCDF4 import Dataset\n",
    "\n",
    "# open the dataset\n",
    "data = Dataset('pr_2001.nc')\n",
    "\n",
    "# print the dimensions of the dataset\n",
    "print(data.dimensions.keys())\n",
    "\n",
    "# print the variables in the dataset\n",
    "print(data.variables.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5fda6e",
   "metadata": {},
   "source": [
    "# The code provided will convert the Net file into an Excel file, containing all the coordinates data for the stations. Once you have this data, create a separate Excel file with these coordinates. Use GIS (Geographic Information System) to identify which coordinate is closest to your observation station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b98e65bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset, num2date\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def process_file(file_path, output_dir):\n",
    "    # open the dataset\n",
    "    data = Dataset(file_path)\n",
    "\n",
    "    # extract the latitude, longitude, precipitation, and time data\n",
    "    lats = data.variables['lat'][:]\n",
    "    lons = data.variables['lon'][:]\n",
    "    days = data.variables['day'][:]\n",
    "    precipitation = data.variables['precipitation_amount'][:]\n",
    "\n",
    "    # Convert days to date objects using the correct units and calendar\n",
    "    time_values = num2date(days[:], units='days since 1900-01-01 00:00:00', calendar='gregorian')\n",
    "\n",
    "    # specify the bounding box of your area of interest\n",
    "    lat_bounds = [33.6838931052876, 34.309164625266]  # MinY, MaxY\n",
    "    lon_bounds = [-84.6287677916827, -83.8396988945535]  # MinX, MaxX\n",
    "\n",
    "    # find the indices that fall within these bounds\n",
    "    lat_inds = np.where((lats >= lat_bounds[0]) & (lats <= lat_bounds[1]))[0]\n",
    "    lon_inds = np.where((lons >= lon_bounds[0]) & (lons <= lon_bounds[1]))[0]\n",
    "\n",
    "    # Convert indices to slices\n",
    "    lat_slice = slice(lat_inds[0], lat_inds[-1] + 1)\n",
    "    lon_slice = slice(lon_inds[0], lon_inds[-1] + 1)\n",
    "\n",
    "    # extract the precipitation data for your area of interest\n",
    "    precip_subset = precipitation[:, lat_slice, lon_slice]\n",
    "\n",
    "    # create arrays for storing the data\n",
    "    time_list = []\n",
    "    lats_list = []\n",
    "    lons_list = []\n",
    "    precip_list = []\n",
    "\n",
    "    # loop through time dimension\n",
    "    for t_idx, t_value in enumerate(time_values):\n",
    "        # create latitude and longitude arrays matching the shape of precip_subset\n",
    "        lats_subset, lons_subset = np.meshgrid(lats[lat_slice], lons[lon_slice])\n",
    "        \n",
    "        # flatten the arrays\n",
    "        lats_flat = lats_subset.flatten()\n",
    "        lons_flat = lons_subset.flatten()\n",
    "        precip_flat = precip_subset[t_idx].flatten()\n",
    "        \n",
    "        # append to the lists\n",
    "        time_list.extend([t_value]*len(precip_flat))\n",
    "        lats_list.extend(lats_flat)\n",
    "        lons_list.extend(lons_flat)\n",
    "        precip_list.extend(precip_flat)\n",
    "\n",
    "    # create a dataframe\n",
    "    df = pd.DataFrame({'Day': time_list, 'Latitude': lats_list, 'Longitude': lons_list, 'Precipitation': precip_list})\n",
    "\n",
    "    # create output file path\n",
    "    output_filename = os.path.splitext(os.path.basename(file_path))[0] + '_data.csv'\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "    # save to csv\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "# Specify directory with your netCDF files\n",
    "input_dir = r'C:\\Users\\as22dt\\Downloads\\Climate\\Precipitation'\n",
    "\n",
    "\n",
    "# Specify directory for the output CSV files\n",
    "output_dir = r'C:\\Users\\as22dt\\Downloads\\Climate\\Precipitation'\n",
    "\n",
    "# Loop through files and process them\n",
    "for year in range(2001, 2024):\n",
    "    file_name = f'pr_{year}.nc'\n",
    "    file_path = os.path.join(input_dir, file_name)\n",
    "    process_file(file_path, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2575adb8",
   "metadata": {},
   "source": [
    "# After converting the Net file into Excel, select the coordinate closest to your station. Then, create an Excel file corresponding to the number of data coordinates you require. For instance, if you have one coordinate, name the Excel file '1'; if you have two coordinates, create two files named '1' and '2'. In each Excel file, include two columns: Latitude and Longitude, representing the data of the station you are interested in. Once this is done, run the code provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f375804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from pathlib import Path\n",
    "\n",
    "# Read precipitation data\n",
    "pr_files = [f\"pr_{year}_data\" for year in range(2001, 2024)]\n",
    "pr_data = pd.concat([pd.read_csv(file + '.csv') for file in pr_files])\n",
    "\n",
    "# Round latitude and longitude in pr_data\n",
    "pr_data['Latitude'] = pr_data['Latitude'].round(6)\n",
    "pr_data['Longitude'] = pr_data['Longitude'].round(6)\n",
    "\n",
    "# Convert wind_speed to numeric\n",
    "if 'Precipitation' in pr_data.columns:\n",
    "    pr_data['Precipitation'] = pd.to_numeric(pr_data['Precipitation'], errors='coerce')\n",
    "\n",
    "# Loop through the files Number of file Like 1,2,3,4....\n",
    "for file_number in [1]:\n",
    "    # Read latitude and longitude from the file\n",
    "    lat_lon_file = pd.read_excel(f\"{file_number}.xlsx\")\n",
    "\n",
    "    # Round latitude and longitude in lat_lon_file\n",
    "    lat_lon_file['Latitude'] = lat_lon_file['Latitude'].round(6)\n",
    "    lat_lon_file['Longitude'] = lat_lon_file['Longitude'].round(6)\n",
    "\n",
    "    # Convert wind_speed to numeric (if it's present in this file too)\n",
    "    if 'Precipitation' in lat_lon_file.columns:\n",
    "        lat_lon_file['Precipitation'] = pd.to_numeric(lat_lon_file['Precipitation'], errors='coerce')\n",
    "\n",
    "    # Merge the data based on latitude and longitude\n",
    "    merged_data = pd.merge(lat_lon_file, pr_data, how='inner', on=['Latitude', 'Longitude'])\n",
    "\n",
    "    # Check if merged_data is empty\n",
    "    if merged_data.empty:\n",
    "        print(f\"No matching data for file {file_number}\")\n",
    "        continue\n",
    "\n",
    "    # Write the data to a new Excel file with two sheets\n",
    "    output_file = Path(f\"{file_number}.xlsx\")\n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        lat_lon_file.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "        merged_data[['Day', 'Latitude', 'Longitude', 'Precipitation']].to_excel(writer, sheet_name='Sheet2', index=False)\n",
    "\n",
    "print(\"Files processed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
